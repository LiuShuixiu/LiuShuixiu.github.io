(window.webpackJsonp=window.webpackJsonp||[]).push([[22],{378:function(_,t,v){"use strict";v.r(t);var a=v(14),r=Object(a.a)({},(function(){var _=this,t=_._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[t("blockquote",[t("p",[t("a",{attrs:{href:"https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html",target:"_blank",rel:"noopener noreferrer"}},[_._v("4.4. 模型选择、欠拟合和过拟合 — 动手学深度学习 2.0.0 documentation (d2l.ai) (opens new window)"),t("OutboundLink")],1)])]),_._v(" "),t("p",[_._v("作为机器学习科学家，我们的目标是发现_模式_（pattern）。 但是，我们如何才能确定模型是真正发现了一种泛化的模式， 而不是简单地记住了数据呢？ 例如，我们想要在患者的基因数据与痴呆状态之间寻找模式， 其中标签是从集合痴呆轻度认知障碍健康{痴呆,轻度认知障碍,健康}中提取的。 因为基因可以唯一确定每个个体（不考虑双胞胎）， 所以在这个任务中是有可能记住整个数据集的。")]),_._v(" "),t("p",[_._v("我们不想让模型只会做这样的事情：“那是鲍勃！我记得他！他有痴呆症！”。 原因很简单：当我们将来部署该模型时，模型需要判断从未见过的患者。 只有当模型真正发现了一种泛化模式时，才会作出有效的预测。")]),_._v(" "),t("p",[_._v("更正式地说，我们的目标是发现某些模式， 这些模式捕捉到了我们训练集潜在总体的规律。 如果成功做到了这点，即使是对以前从未遇到过的个体， 模型也可以成功地评估风险。 如何发现可以泛化的模式是机器学习的根本问题。")]),_._v(" "),t("p",[_._v("困难在于，当我们训练模型时，我们只能访问数据中的小部分样本。 最大的公开图像数据集包含大约一百万张图像。 而在大部分时候，我们只能从数千或数万个数据样本中学习。 在大型医院系统中，我们可能会访问数十万份医疗记录。 当我们使用有限的样本时，可能会遇到这样的问题： 当收集到更多的数据时，会发现之前找到的明显关系并不成立。")]),_._v(" "),t("p",[_._v("将模型在训练数据上拟合的比在潜在分布中更接近的现象称为_过拟合_（overfitting）， 用于对抗过拟合的技术称为_正则化_（regularization）。 在前面的章节中，有些读者可能在用Fashion-MNIST数据集做实验时已经观察到了这种过拟合现象。 在实验中调整模型架构或超参数时会发现： 如果有足够多的神经元、层数和训练迭代周期， 模型最终可以在训练集上达到完美的精度，此时测试集的准确性却下降了。")]),_._v(" "),t("h2",{attrs:{id:"_1-训练误差与泛化误差"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-训练误差与泛化误差"}},[_._v("#")]),_._v(" 1.训练误差与泛化误差")]),_._v(" "),t("p",[t("em",[_._v("训练误差")]),_._v("（training error）是指， 模型在训练数据集上计算得到的误差。")]),_._v(" "),t("p",[t("em",[_._v("泛化误差")]),_._v("（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。 我们永远也无法计算出泛化误差，只能通过将模型应用给一个独立的测试集来估计泛化误差。")]),_._v(" "),t("h3",{attrs:{id:"_1-1-统计学习理论"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-统计学习理论"}},[_._v("#")]),_._v(" 1.1 统计学习理论")]),_._v(" "),t("p",[_._v("在我们目前已探讨、并将在之后继续探讨的监督学习情景中， 我们假设训练数据和测试数据都是从相同的分布中独立提取的。 这通常被称为_独立同分布假设_（i.i.d. assumption）， 这意味着对数据进行采样的过程没有进行“记忆”。 换句话说，抽取的第2个样本和第3个样本的相关性， 并不比抽取的第2个样本和第200万个样本的相关性更强。 但是现实不是一直独立同分布的，我们只能在稍微违背这个假设前提下研究模型。")]),_._v(" "),t("h3",{attrs:{id:"_1-2-模型的复杂性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-模型的复杂性"}},[_._v("#")]),_._v(" 1.2 模型的复杂性")]),_._v(" "),t("p",[_._v("当我们有简单的模型和大量的数据时，我们期望泛化误差与训练误差相近。 当我们有更复杂的模型和更少的样本时，我们预计训练误差会下降，但泛化误差会增大。 模型复杂性由什么构成是一个复杂的问题。 一个模型是否能很好地泛化取决于很多因素。 例如，具有更多参数的模型可能被认为更复杂， 参数有更大取值范围的模型可能更为复杂。 通常对于神经网络，我们认为需要更多训练迭代的模型比较复杂， 而需要_早停_（early stopping）的模型（即较少训练迭代周期）就不那么复杂。")]),_._v(" "),t("p",[_._v("我们很难比较本质上不同大类的模型之间（例如，决策树与神经网络）的复杂性。 就目前而言，一条简单的经验法则相当有用： "),t("strong",[_._v("统计学家认为，能够轻松解释任意事实的模型是复杂的， 而表达能力有限但仍能很好地解释数据的模型可能更有现实用途。")]),_._v("  在哲学上，这与波普尔的科学理论的可证伪性标准密切相关： 如果一个理论能拟合数据，且有具体的测试可以用来证明它是错误的，那么它就是好的。 这一点很重要，因为所有的统计估计都是_事后归纳_。 也就是说，我们在观察事实之后进行估计，因此容易受到相关谬误的影响。 目前，我们将把哲学放在一边，坚持更切实的问题")]),_._v(" "),t("p",[_._v("几个倾向于影响泛化的因素：")]),_._v(" "),t("ol",[t("li",[_._v("可调整参数的数量。当可调整参数的数量（有时称为_自由度_）很大时，模型往往更容易过拟合。")]),_._v(" "),t("li",[_._v("参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。")]),_._v(" "),t("li",[_._v("训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。")])]),_._v(" "),t("h2",{attrs:{id:"_2-模型选择"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-模型选择"}},[_._v("#")]),_._v(" 2.模型选择")]),_._v(" "),t("p",[_._v("在机器学习中，我们通常在评估几个候选模型后选择最终的模型。 这个过程叫做_模型选择_。 有时，需要进行比较的模型在本质上是完全不同的（比如，决策树与线性模型）。 又有时，我们需要比较不同的超参数设置下的同一类模型（在深度学习中经常使用）。")]),_._v(" "),t("p",[_._v("例如，训练多层感知机模型时，我们可能希望比较具有不同数量的隐藏层、不同数量的隐藏单元以及不同的激活函数组合的模型。 为了确定候选模型中的最佳模型，我们通常会使用验证集。")]),_._v(" "),t("h3",{attrs:{id:"_2-1-验证集"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-验证集"}},[_._v("#")]),_._v(" 2.1 验证集")]),_._v(" "),t("p",[_._v("原则上，在我们确定所有的超参数之前，我们不希望用到测试集。 如果我们在模型选择过程中使用测试数据，可能会有过拟合测试数据的风险，那就麻烦大了。 如果我们过拟合了训练数据，还可以在测试数据上的评估来判断过拟合。 但是如果我们过拟合了测试数据，我们又该怎么知道呢？")]),_._v(" "),t("p",[_._v("解决此问题的常见做法是将我们的数据分成三份， 除了训练和测试数据集之外，还增加一个_验证数据集_（validation dataset）， 也叫_验证集_（validation set）。")]),_._v(" "),t("h3",{attrs:{id:"_2-2-k折交叉验证"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-k折交叉验证"}},[_._v("#")]),_._v(" 2.2 K折交叉验证")]),_._v(" "),t("p",[_._v("当训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集。 这个问题的一个流行的解决方案是采用K折交叉验证*。 这里，原始训练数据被分成K个不重叠的子集。 然后执行K次模型训练和验证，每次在K−1个子集上进行训练， 并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。 最后，通过对K次实验的结果取平均来估计训练和验证误差。")]),_._v(" "),t("h2",{attrs:{id:"_3-欠拟合与过拟合"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-欠拟合与过拟合"}},[_._v("#")]),_._v(" 3.欠拟合与过拟合")]),_._v(" "),t("p",[_._v("当我们比较训练和验证误差时，我们要注意两种常见的情况。 首先，我们要注意这样的情况：训练误差和验证误差都很严重， 但它们之间仅有一点差距。 如果模型不能降低训练误差，这可能意味着模型过于简单（即表达能力不足）， 无法捕获试图学习的模式。 此外，由于我们的训练和验证误差之间的_泛化误差_很小， 我们有理由相信可以用一个更复杂的模型降低训练误差。 这种现象被称为_欠拟合_（underfitting）。")]),_._v(" "),t("p",[_._v("另一方面，当我们的训练误差明显低于验证误差时要小心， 这表明严重的_过拟合_（overfitting）。 注意，_过拟合_并不总是一件坏事。 特别是在深度学习领域，众所周知， 最好的预测模型在训练数据上的表现往往比在保留（验证）数据上好得多。 最终，我们通常更关心验证误差，而不是训练误差和验证误差之间的差距。（即泛化能力）")]),_._v(" "),t("h3",{attrs:{id:"_3-1-模型的复杂性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-模型的复杂性"}},[_._v("#")]),_._v(" 3.1 模型的复杂性")]),_._v(" "),t("p",[_._v("给定由单个特征x和对应实数标签x组成的训练数据， 我们试图找到下面的d阶多项式来估计标签y。")]),_._v(" "),t("p",[_._v("y^=∑i=0dxiwi")]),_._v(" "),t("p",[_._v("这只是一个线性回归问题，我们的特征是x的幂给出的， 模型的权重是wi给出的，偏置是w0给出的 （因为对于所有的x都有x0=1）。 由于这只是一个线性回归问题，我们可以使用平方误差作为我们的损失函数。")]),_._v(" "),t("p",[_._v("高阶多项式函数比低阶多项式函数复杂得多。 高阶多项式的参数较多，模型函数的选择范围较广。 因此在固定训练数据集的情况下， 高阶多项式函数相对于低阶多项式的训练误差应该始终更低（最坏也是相等）。 事实上，当数据样本包含了x的不同值时， 函数阶数等于数据样本数量的多项式函数可以完美拟合训练集。 在下图中， 我们直观地描述了多项式的阶数和欠拟合与过拟合之间的关系。")]),_._v(" "),t("p",[t("img",{attrs:{src:"https://zh-v2.d2l.ai/_images/capacity-vs-error.svg",alt:""}})]),_._v(" "),t("h3",{attrs:{id:"_3-2-数据集的大小"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-数据集的大小"}},[_._v("#")]),_._v(" 3.2 数据集的大小")]),_._v(" "),t("p",[_._v("另一个重要因素是数据集的大小。 训练数据集中的样本越少，我们就越有可能（且更"),t("strong",[_._v("严重")]),_._v("地）过拟合。 随着训练数据量的增加，泛化误差通常会减小。 此外，一般来说，更多的数据不会有什么坏处。 对于固定的任务和数据分布，模型复杂性和数据集大小之间通常存在关系。 给出更多的数据，我们可能会尝试拟合一个更复杂的模型。 能够拟合更复杂的模型可能是有益的。 如果没有足够的数据，简单的模型可能更有用。 对于许多任务，深度学习只有在有数千个训练样本时才优于线性模型。 从一定程度上来说，深度学习目前的生机要归功于 廉价存储、互联设备以及数字化经济带来的海量数据集。")]),_._v(" "),t("h2",{attrs:{id:"_4-总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-总结"}},[_._v("#")]),_._v(" 4.总结")]),_._v(" "),t("ul",[t("li",[_._v("欠拟合是指模型无法继续减少训练误差。过拟合是指训练误差远小于验证误差。")]),_._v(" "),t("li",[_._v("由于不能基于训练误差来估计泛化误差，因此简单地最小化训练误差并不一定意味着泛化误差的减小。机器学习模型需要注意防止过拟合，即防止泛化误差过大。")]),_._v(" "),t("li",[_._v("验证集可以用于模型选择，但不能过于随意地使用它。")]),_._v(" "),t("li",[_._v("我们应该选择一个复杂度适当的模型，避免使用数量不足的训练样本")])])])}),[],!1,null,null,null);t.default=r.exports}}]);